ylab="Normalized value",
ylim=c(0.6,1.2))
rect(2000,0.6,2004,1.2, col="grey", border="transparent")
points(sum.la.agg2$d.norm~sum.la.agg2$YR, type="p", pch=0)
points(sum.la.agg2$J.norm~sum.la.agg2$YR, type="p", pch=1)
points(sum.la.agg2$shan.norm~sum.la.agg2$YR, type="p", pch=2)
points(sum.la.agg2$simp.norm~sum.la.agg2$YR, type="p", pch=5)
lines(lowess(sum.la.agg2$d.norm~sum.la.agg2$YR), lty=1, col=26, lwd=1.8)
lines(lowess(sum.la.agg2$J.norm~sum.la.agg2$YR), lty=2, col=51, lwd=1.8)
lines(lowess(sum.la.agg2$shan.norm~sum.la.agg2$YR), lty=3, col=76, lwd=1.8)
lines(lowess(sum.la.agg2$simp.norm~sum.la.agg2$YR), lty=4, col=101, lwd=1.8)
#lines(lowess(sum.la.agg2$N1.norm~sum.la.agg2$YR), lty=5, col=126, lwd=1.8)
#lines(lowess(sum.la.agg2$N2.norm~sum.la.agg2$YR), lty=6, col=151, lwd=1.8)
grid(col="lightgrey")
# abline(v=2003,col=4,lty=2)
# abline(v=1996,col=9,lty=2) #hypoxia
text(2011.3, 1.2, "A", cex=1,font=2)
#la fall
plot(fall.la.agg2$S.norm~fall.la.agg2$YR, pch="",
#main="Louisiana Fall",
xlab="Year",
ylab="Normalized value",
ylim=c(0.6,1.45))
rect(2000,0,2004,2, col="grey", border="transparent")
points(fall.la.agg2$d.norm~fall.la.agg2$YR, type="p", pch=0)
points(fall.la.agg2$J.norm~fall.la.agg2$YR, type="p", pch=1)
points(fall.la.agg2$shan.norm~fall.la.agg2$YR, type="p", pch=2)
points(fall.la.agg2$simp.norm~fall.la.agg2$YR, type="p", pch=5)
#points(fall.la.agg2$N.norm.mean~fall.la.agg2$YR, type="p", pch=2)
lines(lowess(fall.la.agg2$d.norm~fall.la.agg2$YR), lty=1, col=26, lwd=1.8)
lines(lowess(fall.la.agg2$J.norm~fall.la.agg2$YR), lty=2, col=51, lwd=1.8)
lines(lowess(fall.la.agg2$shan.norm~fall.la.agg2$YR), lty=3, col=76, lwd=1.8)
lines(lowess(fall.la.agg2$simp.norm~fall.la.agg2$YR), lty=4, col=101, lwd=1.8)
#lines(lowess(fall.la.agg2$N1.norm~fall.la.agg2$YR), lty=5, col=126, lwd=1.8)
#lines(lowess(fall.la.agg2$N2.norm~fall.la.agg2$YR), lty=6, col=151, lwd=1.8)
grid(col="lightgrey")
# abline(v=2003,col=4,lty=2)
# abline(v=1996,col=9,lty=2) #hypoxia
text(2011.3, 1.45, "B", cex=1,font=2)
#tx summer
plot(sum.tx.agg2$S.norm~sum.tx.agg2$YR, pch="",
#main="Texas Summer",
xlab="Year",
ylab="Normalized value",
ylim=c(0.6,1.2))
rect(2002,0,2003,2, col="grey", border="transparent")
points(sum.tx.agg2$d.norm~sum.tx.agg2$YR, type="p", pch=0)
points(sum.tx.agg2$J.norm~sum.tx.agg2$YR, type="p", pch=1)
points(sum.tx.agg2$shan.norm~sum.tx.agg2$YR, type="p", pch=2)
points(sum.tx.agg2$simp.norm~sum.tx.agg2$YR, type="p", pch=5)
#points(sum.tx.agg2$N.norm.mean~sum.tx.agg2$YR, type="p", pch=2)
lines(lowess(sum.tx.agg2$d.norm~sum.tx.agg2$YR), lty=1, col=26, lwd=1.8)
lines(lowess(sum.tx.agg2$J.norm~sum.tx.agg2$YR), lty=2, col=51, lwd=1.8)
lines(lowess(sum.tx.agg2$shan.norm~sum.tx.agg2$YR), lty=3, col=76, lwd=1.8)
lines(lowess(sum.tx.agg2$simp.norm~sum.tx.agg2$YR), lty=4, col=101, lwd=1.8)
#lines(lowess(sum.tx.agg2$N1.norm~sum.tx.agg2$YR), lty=5, col=126, lwd=1.8)
#lines(lowess(sum.tx.agg2$N2.norm~sum.tx.agg2$YR), lty=6, col=151, lwd=1.8)
grid(col="lightgrey")
# abline(v=2003,col=4,lty=2)
# abline(v=1996,col=9,lty=2) #hypoxia
text(2011.3, 1.2, "C", cex=1,font=2)
#tx fall
plot(fall.tx.agg2$S.norm~fall.tx.agg2$YR, pch="",
#main="Texas Fall",
xlab="Year",
ylab="Normalized value",
ylim=c(0.6,1.2))
rect(1995,0,2000,2, col="grey", border="transparent")
points(fall.tx.agg2$d.norm~fall.tx.agg2$YR, type="p", pch=0)
points(fall.tx.agg2$J.norm~fall.tx.agg2$YR, type="p", pch=1)
points(fall.tx.agg2$shan.norm~fall.tx.agg2$YR, type="p", pch=2)
points(fall.tx.agg2$simp.norm~fall.tx.agg2$YR, type="p", pch=5)
#points(fall.tx.agg2$N.norm.mean~fall.tx.agg2$YR, type="p", pch=2)
lines(lowess(fall.tx.agg2$d.norm~fall.tx.agg2$YR), lty=1, col=26, lwd=1.8)
lines(lowess(fall.tx.agg2$J.norm~fall.tx.agg2$YR), lty=2, col=51, lwd=1.8)
lines(lowess(fall.tx.agg2$shan.norm~fall.tx.agg2$YR), lty=3, col=76, lwd=1.8)
lines(lowess(fall.tx.agg2$simp.norm~fall.tx.agg2$YR), lty=4, col=101, lwd=1.8)
#lines(lowess(fall.tx.agg2$N1.norm~fall.tx.agg2$YR), lty=5, col=126, lwd=1.8)
#lines(lowess(fall.tx.agg2$N2.norm~fall.tx.agg2$YR), lty=6, col=151, lwd=1.8)
grid(col="lightgrey")
# abline(v=2003,col=4,lty=2)
# abline(v=1996,col=9,lty=2) #hypoxia
text(2011.3, 1.2, "D", cex=1,font=2)
install.packages("PopGenReport")
require(PopGenReport)
data(bilby) #this loads some sample data
popgenreport(bilby) #if you installed LaTeX
getwd()
opts_knit$set
opts_knit$set(echo=FALSE)
opts_knit
install.packages(c("dplyr", "fields", "foreign", "gtools", "knitcitations", "lme4", "mapproj", "maptools", "markdown", "Matrix", "mgcv", "minqa", "multcomp", "mvtnorm", "permute", "Rcpp", "RcppEigen", "rfisheries", "rpart", "survival", "texreg", "TH.data", "yaml"))
install.packages("RefManagerR")
install.packages(c("plyr", "spam"))
install.packages("pdfetch")
oldBreakpt(biomass.dat,1,2)
source("C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\EcosysMetricsGOM\\functions\\oldBreakpt.R")
oldBreakpt(biomass.dat,1,2)
shrcom.agg2<-aggregate(effort~ yr, data=shrcom.agg, FUN=sum)
shrcom.agg2<-subset(shrcom.agg2, shrcom.agg2$yr>=1987)
shrcom<-data.frame(shrcom.agg2$effort, shrcom.agg2$yr)
colnames(shrcom)[1]<-'y'
colnames(shrcom)[2]<-'x'
biomass.dat<-aggregate(cpue~YR, data=complete.dat, FUN=mean)
abundance.dat<-aggregate(catch_cpue~YR, data=complete.dat, FUN=mean)
biomass.sm<-as.data.frame(lowess(biomass.dat$cpue~biomass.dat$YR))
shrcom.agg2<-aggregate(effort~ yr, data=shrcom.agg, FUN=sum)
shrcom.agg<-read.csv("C:/Users/kevin.purcell/Documents/comm_analysis/DiversityMetrics/metrics_v2/offshore_6011.csv")
shrcom.agg2<-aggregate(effort~ yr, data=shrcom.agg, FUN=sum)
shrcom.agg2<-subset(shrcom.agg2, shrcom.agg2$yr>=1987)
shrcom<-data.frame(shrcom.agg2$effort, shrcom.agg2$yr)
colnames(shrcom)[1]<-'y'
colnames(shrcom)[2]<-'x'
biomass.dat<-aggregate(cpue~YR, data=complete.dat, FUN=mean)
# Take the bgs record and merge with jkc.fish to narrow to only species of interest
bgsrec.dat2<-merge(bgsrec.dat, jkc.fish, by="BIO_BGS") #merge with the list of keepers
bgsrec.dat2<-merge(bgsrec.dat2, specinfo.dat, by="BIO_BGS") #tags each bsg record as p or d
bgsrec.dat2<-merge(bgsrec.dat2, invrec.dat, by=intersect(names(bgsrec.dat2), names(invrec.dat)))
bgsrec.dat2<-merge(bgsrec.dat2, starec.dat, by=intersect(names(bgsrec.dat2), names(starec.dat)))
#table<-merge(jkc.fish, specinfo.dat, by="BIO_BGS")
#write.table(table,"spec_list_review.csv",sep=",",row.names=T,col.names=T,quote=F) #changed this to row.names TRUE
bgsrec.dat2<-subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD!='NA') #ditch NAs for spd
bgsrec.dat2<-subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD<30) # ditch the vessel speed marked as 30
bgsrec.dat2<-subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD>0)
# might want to standardize to a standard tow duration
#relabel min_fish -9 to NA
bgsrec.dat2$MIN_FISH[bgsrec.dat2$MIN_FISH==(-9)]=NA
bgsrec.dat2<- subset(bgsrec.dat2, bgsrec.dat2$MIN_FISH!='NA') #ditch NAs for min fish
#calculate median tow time
st.tow<-median(bgsrec.dat2$MIN_FISH)
#calculate effort vector for each catch entry
bgsrec.dat2$effort<-(bgsrec.dat2$MIN_FISH*bgsrec.dat2$VESSEL_SPD)
bgsrec.dat2$wt_per_min<-(bgsrec.dat2$SELECT_BGS/bgsrec.dat2$MIN_FISH)
bgsrec.dat2$c_per_min<-(bgsrec.dat2$CNTEXP/bgsrec.dat2$MIN_FISH)
bgsrec.dat2$ST_SELECT_BGS<-(bgsrec.dat2$wt_per_min*st.tow)
bgsrec.dat2$ST_CNTEXP<-(bgsrec.dat2$c_per_min*st.tow)
#calculate effort vector for each catch entry
bgsrec.dat2$cpue<-bgsrec.dat2$ST_SELECT_BGS/bgsrec.dat2$effort
bgsrec.dat2$catch_cpue<-bgsrec.dat2$ST_CNTEXP/bgsrec.dat2$effort
names(bgsrec.dat2)
length(unique(bgsrec.dat2$BIO_BGS))
bgsrec.dat2$taxid<-paste(bgsrec.dat2$Genus, bgsrec.dat2$Species, sep=".")
complete.dat<-bgsrec.dat2
source("C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\EcosysMetricsGOM\\Analysis\\ResultsFigures\\figure1.R")
oldBreakpt(shrcom.agg2,1,2)
#load packages
library(reshape)
library(lattice)
library(MASS)
###Data Import and limiting source files########
starec.dat <- read.csv("C:/Users/kevin.purcell/Documents/seamap_2013/STAREC.csv")
#create a yr and month variable
starec.dat$date<-starec.dat$MO_DAY_YR
starec.dat$date<-as.Date(starec.dat$date, "%m/%d/%Y")
starec.dat$month<-format(starec.dat$date, format="%m")
starec.dat$YR<-format(starec.dat$date, format="%Y")
starec.dat$YR<-as.numeric(starec.dat$YR)
starec.dat$month<-as.numeric(starec.dat$month)
starec.dat <- starec.dat[,c(1:7, 14:17, 24:33, 36:40, 42:51)]  #ditch the columns that screw stuff up.
starec.dat$STAT_ZONE[starec.dat$STAT_ZONE==(-9)]=NA
starec.dat<- subset(starec.dat, starec.dat$STAT_ZONE!='NA') #ditch NAs for min fish
starec.dat<- subset(starec.dat, starec.dat$STAT_ZONE>=1&starec.dat$STAT_ZONE<=21)
summary(starec.dat)
# envrec.dat <- read.csv("C:/Users/kevin.purcell/Documents/seamap_2013/ENVREC.csv")
# names(envrec.dat)
# envrec.dat <- envrec.dat[,c(1:31)]
invrec.dat <- read.csv("C:/Users/kevin.purcell/Documents/seamap_2013/INVREC.csv")
names(invrec.dat)
invrec.dat <- invrec.dat[,c(2,11)]
bgsrec.dat<- read.csv("C:/Users/kevin.purcell/Documents/seamap_2013/BGSREC.csv")
specinfo.dat<-read.csv("C:/Users/kevin.purcell/Documents/comm_analysis/spec_info_summary.csv")
colnames(specinfo.dat)[1]<-'BIO_BGS'
bycatch.dat<-read.csv("C:/Users/kevin.purcell/Documents/comm_analysis/bycatch_status.csv")
bycatch.dat$TAXONOMIC<-NULL
bycatch.dat$common_name<-NULL
specinfo.dat<-merge(specinfo.dat, bycatch.dat, by="BIO_BGS", all.x=T)
# This is the fish we want to focus on
jkc.fish<-read.csv("C:/Users/kevin.purcell/Documents/comm_analysis/seamap_keepers_comm_analysis.csv")  #list of species of importance
info.dat<-merge(jkc.fish, specinfo.dat, by="BIO_BGS")
#####
# Take the bgs record and merge with jkc.fish to narrow to only species of interest
bgsrec.dat2<-merge(bgsrec.dat, jkc.fish, by="BIO_BGS") #merge with the list of keepers
bgsrec.dat2<-merge(bgsrec.dat2, specinfo.dat, by="BIO_BGS") #tags each bsg record as p or d
bgsrec.dat2<-merge(bgsrec.dat2, invrec.dat, by=intersect(names(bgsrec.dat2), names(invrec.dat)))
bgsrec.dat2<-merge(bgsrec.dat2, starec.dat, by=intersect(names(bgsrec.dat2), names(starec.dat)))
# table<-merge(jkc.fish, specinfo.dat, by="BIO_BGS")
# write.table(table,"spec_list_review.csv",sep=",",row.names=T,col.names=T,quote=F) #changed this to row.names TRUE
bgsrec.dat2<-subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD!='NA') #ditch NAs for spd
bgsrec.dat2<-subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD<30) # ditch the vessel speed marked as 30
bgsrec.dat2<-subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD>0)
bgsrec.dat2<-subset(bgsrec.dat2, bgsrec.dat2$YR>=1987&bgsrec.dat2$YR<=2011)  #focus on good data years
# might want to standardize to a standard tow duration
#relabel min_fish -9 to NA
bgsrec.dat2$MIN_FISH[bgsrec.dat2$MIN_FISH==(-9)]=NA
bgsrec.dat2<- subset(bgsrec.dat2, bgsrec.dat2$MIN_FISH!='NA') #ditch NAs for min fish
bgsrec.dat2<- subset(bgsrec.dat2, bgsrec.dat2$MIN_FISH<=200)
#calculate median tow time
st.tow<-median(bgsrec.dat2$MIN_FISH)
#calculate effort vector for each catch entry
bgsrec.dat2$effort<-(bgsrec.dat2$MIN_FISH*bgsrec.dat2$VESSEL_SPD)
bgsrec.dat2$wt_per_min<-(bgsrec.dat2$SELECT_BGS/bgsrec.dat2$MIN_FISH)
bgsrec.dat2$c_per_min<-(bgsrec.dat2$CNTEXP/bgsrec.dat2$MIN_FISH)
bgsrec.dat2$ST_SELECT_BGS<-(bgsrec.dat2$wt_per_min*st.tow)
bgsrec.dat2$ST_CNTEXP<-(bgsrec.dat2$c_per_min*st.tow)
#make proportions??
#calculate effort vector for each catch entry
bgsrec.dat2$cpue<-bgsrec.dat2$ST_SELECT_BGS/bgsrec.dat2$effort
bgsrec.dat2$catch_cpue<-bgsrec.dat2$ST_CNTEXP/bgsrec.dat2$effort
names(bgsrec.dat2)
length(unique(bgsrec.dat2$BIO_BGS))
bgsrec.dat2$label<- paste(bgsrec.dat2$Trophic_Level, bgsrec.dat2$TAXONOMIC, sep=".")
biomass.dat<-aggregate(cpue~YR, data=complete.dat, FUN=mean)
abundance.dat<-aggregate(catch_cpue~YR, data=complete.dat, FUN=mean)
biomass.sm<-as.data.frame(lowess(biomass.dat$cpue~biomass.dat$YR))
bgsrec.dat2<-merge(bgsrec.dat, jkc.fish, by="BIO_BGS") #merge with the list of keepers
bgsrec.dat2<-merge(bgsrec.dat2, specinfo.dat, by="BIO_BGS") #tags each bsg record as p or d
bgsrec.dat2<-merge(bgsrec.dat2, invrec.dat, by=intersect(names(bgsrec.dat2), names(invrec.dat)))
bgsrec.dat2<-merge(bgsrec.dat2, starec.dat, by=intersect(names(bgsrec.dat2), names(starec.dat)))
#table<-merge(jkc.fish, specinfo.dat, by="BIO_BGS")
#write.table(table,"spec_list_review.csv",sep=",",row.names=T,col.names=T,quote=F) #changed this to row.names TRUE
bgsrec.dat2<-subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD!='NA') #ditch NAs for spd
bgsrec.dat2<-subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD<30) # ditch the vessel speed marked as 30
bgsrec.dat2<-subset(bgsrec.dat2, bgsrec.dat2$VESSEL_SPD>0)
# might want to standardize to a standard tow duration
#relabel min_fish -9 to NA
bgsrec.dat2$MIN_FISH[bgsrec.dat2$MIN_FISH==(-9)]=NA
bgsrec.dat2<- subset(bgsrec.dat2, bgsrec.dat2$MIN_FISH!='NA') #ditch NAs for min fish
#calculate median tow time
st.tow<-median(bgsrec.dat2$MIN_FISH)
#calculate effort vector for each catch entry
bgsrec.dat2$effort<-(bgsrec.dat2$MIN_FISH*bgsrec.dat2$VESSEL_SPD)
bgsrec.dat2$wt_per_min<-(bgsrec.dat2$SELECT_BGS/bgsrec.dat2$MIN_FISH)
bgsrec.dat2$c_per_min<-(bgsrec.dat2$CNTEXP/bgsrec.dat2$MIN_FISH)
bgsrec.dat2$ST_SELECT_BGS<-(bgsrec.dat2$wt_per_min*st.tow)
bgsrec.dat2$ST_CNTEXP<-(bgsrec.dat2$c_per_min*st.tow)
#calculate effort vector for each catch entry
bgsrec.dat2$cpue<-bgsrec.dat2$ST_SELECT_BGS/bgsrec.dat2$effort
bgsrec.dat2$catch_cpue<-bgsrec.dat2$ST_CNTEXP/bgsrec.dat2$effort
names(bgsrec.dat2)
length(unique(bgsrec.dat2$BIO_BGS))
bgsrec.dat2$taxid<-paste(bgsrec.dat2$Genus, bgsrec.dat2$Species, sep=".")
complete.dat<-bgsrec.dat2
biomass.dat<-aggregate(cpue~YR, data=complete.dat, FUN=mean)
abundance.dat<-aggregate(catch_cpue~YR, data=complete.dat, FUN=mean)
biomass.sm<-as.data.frame(lowess(biomass.dat$cpue~biomass.dat$YR))
oldBreakpt(biomass.dat,1,2)
oldBreakpt(abundance.dat,1,2)
#load packages
library(reshape)
library(lattice)
library(MASS)
library(vegan)
library(doBy)
library(gplots)
library(segmented)
library(pander)
library(knitcitations)
source("C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\EcosysMetricsGOM\\Data\\GatherSource\\importDiversityData.R")
source("C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\EcosysMetricsGOM\\Data\\GatherSource\\mergeDiversityData.R")
# Create seperate dataframes for Regions and seasons
sum.dat<-subset(complete.dat, complete.dat$month>=6&complete.dat$month<=8)
sum.la.dat<-subset(sum.dat, sum.dat$STAT_ZONE>=13&sum.dat$STAT_ZONE<=17)
sum.tx.dat<-subset(sum.dat, sum.dat$STAT_ZONE>=18&sum.dat$STAT_ZONE<=21)
fall.dat<-subset(complete.dat, complete.dat$month>=9&complete.dat$month<=11)
fall.la.dat<-subset(fall.dat, fall.dat$STAT_ZONE>=13&fall.dat$STAT_ZONE<=17)
fall.tx.dat<-subset(fall.dat, fall.dat$STAT_ZONE>=18&fall.dat$STAT_ZONE<=21)
## REFOMAT data.frames for diversity analysis
# Summer Louisiana Timeseries
sum.la.tab<-aggregate(ST_CNTEXP ~ YR + TAXONOMIC, data=sum.la.dat, FUN=sum)
sum.la.tab<-reshape(sum.la.tab, idvar="YR", timevar="TAXONOMIC", direction="wide")
sum.la.tab[is.na(sum.la.tab)]<-0
names(sum.la.tab) <- gsub("ST_CNTEXP.", "", names(sum.la.tab))  #removes the var name from reshape
YR<-sum.la.tab$YR
sum.la.tab$YR<-NULL
# Summer Texas Timeseries
sum.tx.tab<-aggregate(ST_CNTEXP ~ YR + TAXONOMIC, data=sum.tx.dat, FUN=sum)
sum.tx.tab<-reshape(sum.tx.tab, idvar="YR", timevar="TAXONOMIC", direction="wide")
sum.tx.tab[is.na(sum.tx.tab)]<-0
names(sum.tx.tab) <- gsub("ST_CNTEXP.", "", names(sum.tx.tab))  #removes the var name from reshape
YR<-sum.tx.tab$YR
sum.tx.tab$YR<-NULL
# Fall Louisiana Timeseries
fall.la.tab<-aggregate(ST_CNTEXP ~ YR + TAXONOMIC, data=fall.la.dat, FUN=sum)
fall.la.tab<-reshape(fall.la.tab, idvar="YR", timevar="TAXONOMIC", direction="wide")
fall.la.tab[is.na(fall.la.tab)]<-0
names(fall.la.tab) <- gsub("ST_CNTEXP.", "", names(fall.la.tab))  #removes the var name from reshape
YR<-fall.la.tab$YR
fall.la.tab$YR<-NULL
# Fall Texas Timeseries
fall.tx.tab<-aggregate(ST_CNTEXP ~ YR + TAXONOMIC, data=fall.tx.dat, FUN=sum)
fall.tx.tab<-reshape(fall.tx.tab, idvar="YR", timevar="TAXONOMIC", direction="wide")
fall.tx.tab[is.na(fall.tx.tab)]<-0
names(fall.tx.tab) <- gsub("ST_CNTEXP.", "", names(fall.tx.tab))  #removes the var name from reshape
YR<-fall.tx.tab$YR
fall.tx.tab$YR<-NULL
source("C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\EcosysMetricsGOM\\functions\\divMetrics.R")
# calculate diversity metrics
sum.la.agg<-divMetrics(sum.la.tab)
sum.la.agg$mod<-"sum.la"
sum.tx.agg<-divMetrics(sum.tx.tab)
sum.tx.agg$mod<-"sum.tx"
fall.la.agg<-divMetrics(fall.la.tab)
fall.la.agg$mod<-"fall.la"
fall.tx.agg<-divMetrics(fall.tx.tab)
fall.tx.agg$mod<-"fall.tx"
### Piecewise regression
# Create a df for each lowess smooth
sum.la.S<-as.data.frame(lowess(sum.la.agg$S~sum.la.agg$YR));sum.la.S$mod<-"sum.la"
sum.la.d<-as.data.frame(lowess(sum.la.agg$d~sum.la.agg$YR));sum.la.d$mod<-"sum.la"
sum.la.J<-as.data.frame(lowess(sum.la.agg$J~sum.la.agg$YR));sum.la.J$mod<-"sum.la"
sum.la.shan<-as.data.frame(lowess(sum.la.agg$shan~sum.la.agg$YR));sum.la.shan$mod<-"sum.la"
sum.la.simp<-as.data.frame(lowess(sum.la.agg$simp~sum.la.agg$YR));sum.la.simp$mod<-"sum.la"
sum.la.N1<-as.data.frame(lowess(sum.la.agg$N1~sum.la.agg$YR));sum.la.N1$mod<-"sum.la"
sum.la.N2<-as.data.frame(lowess(sum.la.agg$N2~sum.la.agg$YR));sum.la.N2$mod<-"sum.la"
sum.tx.S<-as.data.frame(lowess(sum.tx.agg$S~sum.tx.agg$YR));sum.tx.S$mod<-"sum.tx"
sum.tx.d<-as.data.frame(lowess(sum.tx.agg$d~sum.tx.agg$YR));sum.tx.d$mod<-"sum.tx"
sum.tx.J<-as.data.frame(lowess(sum.tx.agg$J~sum.tx.agg$YR));sum.tx.J$mod<-"sum.tx"
sum.tx.shan<-as.data.frame(lowess(sum.tx.agg$shan~sum.tx.agg$YR));sum.tx.shan$mod<-"sum.tx"
sum.tx.simp<-as.data.frame(lowess(sum.tx.agg$simp~sum.tx.agg$YR));sum.tx.simp$mod<-"sum.tx"
sum.tx.N1<-as.data.frame(lowess(sum.tx.agg$N1~sum.tx.agg$YR));sum.tx.S$N1<-"sum.tx"
sum.tx.N2<-as.data.frame(lowess(sum.tx.agg$N2~sum.tx.agg$YR));sum.tx.S$N2<-"sum.tx"
fall.la.S<-as.data.frame(lowess(fall.la.agg$S~fall.la.agg$YR));fall.la.S$mod<-"fall.la"
fall.la.d<-as.data.frame(lowess(fall.la.agg$d~fall.la.agg$YR));fall.la.d$mod<-"fall.la"
fall.la.J<-as.data.frame(lowess(fall.la.agg$J~fall.la.agg$YR));fall.la.J$mod<-"fall.la"
fall.la.shan<-as.data.frame(lowess(fall.la.agg$shan~fall.la.agg$YR));fall.la.shan$mod<-"fall.la"
fall.la.simp<-as.data.frame(lowess(fall.la.agg$simp~fall.la.agg$YR));fall.la.simp$mod<-"fall.la"
fall.la.N1<-as.data.frame(lowess(fall.la.agg$N1~fall.la.agg$YR));fall.la.N1$mod<-"fall.la"
fall.la.N2<-as.data.frame(lowess(fall.la.agg$N2~fall.la.agg$YR));fall.la.N2$mod<-"fall.la"
fall.tx.S<-as.data.frame(lowess(fall.tx.agg$S~fall.tx.agg$YR));fall.tx.S$mod<-"fall.tx"
fall.tx.d<-as.data.frame(lowess(fall.tx.agg$d~fall.tx.agg$YR));fall.tx.d$mod<-"fall.tx"
fall.tx.J<-as.data.frame(lowess(fall.tx.agg$J~fall.tx.agg$YR));fall.tx.J$mod<-"fall.tx"
fall.tx.shan<-as.data.frame(lowess(fall.tx.agg$shan~fall.tx.agg$YR));fall.tx.shan$mod<-"fall.tx"
fall.tx.simp<-as.data.frame(lowess(fall.tx.agg$simp~fall.tx.agg$YR));fall.tx.simp$mod<-"fall.tx"
fall.tx.N1<-as.data.frame(lowess(fall.tx.agg$N1~fall.tx.agg$YR));fall.tx.N1$mod<-"fall.tx"
fall.tx.N2<-as.data.frame(lowess(fall.tx.agg$N2~fall.tx.agg$YR));fall.tx.N2$mod<-"fall.tx"
shrcom.agg2<-aggregate(effort~ yr, data=shrcom.agg, FUN=sum)
shrcom.agg2<-subset(shrcom.agg2, shrcom.agg2$yr>=1987)
shrcom<-data.frame(shrcom.agg2$effort, shrcom.agg2$yr)
colnames(shrcom)[1]<-'y'
colnames(shrcom)[2]<-'x'
biomass.dat<-aggregate(cpue~YR, data=complete.dat, FUN=mean)
abundance.dat<-aggregate(catch_cpue~YR, data=complete.dat, FUN=mean)
biomass.sm<-as.data.frame(lowess(biomass.dat$cpue~biomass.dat$YR))
source("C:\\Users\\Kevin.Purcell\\Documents\\GitHub\\EcosysMetricsGOM\\functions\\oldBreakpt.R")
oldBreakpt(hypox.area,1,2)
oldBreakpt(shrcom.agg2,1,2)
oldBreakpt(biomass.dat,1,2)
oldBreakpt(abundance.dat,1,2)
library(knitcitations)
graphics.off()
rm(list=ls(all=TRUE))
library(knitcitations)
#load packages
library(reshape)
library(lattice)
library(MASS)
library(mvtsplot)
library(ggplot2)
load("C:/Users/kevin.purcell/Documents/comm_analysis/matrix_plot_update/matrix_data_2013-7-3.RData")
eff.dat<-read.csv("C:/Users/kevin.purcell/Documents/comm_analysis/offshore_6011.csv")
# Make a yearly data set
biomass.plot<-aggregate(ST_SELECT_BGS ~ YR, data=bgsrec.dat2, FUN=mean)
abundance.plot<-aggregate(ST_CNTEXP ~ YR, data=bgsrec.dat2, FUN=mean)
eff.plot<-aggregate(effort ~ yr, data=eff.dat, FUN=sum)
with(biomass.plot, {par(mar=c(5,4,4,5)+.1)
plot(ST_SELECT_BGS ~ YR,
ylab="Biomass",
main="Biomass Trends over SEAMAP survey")
lines(lowess(ST_SELECT_BGS~YR, f=.2))
})
par(mfrow=c(1,2))
qplot(YR,ST_SELECT_BGS, data=biomass.plot,
geom=c("point","smooth"),
ylab="Average Biomass (kg)",
xlab="Year",
main="Average Biomass timeseries for Standard SEAMAP trawl")
qplot(yr, effort, data=eff.plot,
geom=c("point", "smooth"),
ylab="Fishing Effort",
xlab="Year",
main="Total shrimping effort timeseries for nwGOM")
qplot(YR,ST_CNTEXP, data=abundance.plot,
geom=c("point","smooth"),
ylab="Average Abundance",
xlab="Year",
main="Average Abundnace timeseries for Standard SEAMAP trawl")
qplot(YR,ST_SELECT_BGS, data=biomass.plot,
geom=c("point","smooth"),
ylab="Average Biomass (kg)",
xlab="Year",
main="Average Biomass timeseries for Standard SEAMAP trawl")
qplot(yr, effort, data=eff.plot,
geom=c("point", "smooth"),
ylab="Fishing Effort",
xlab="Year",
main="Total shrimping effort timeseries for nwGOM")
qplot(YR,ST_CNTEXP, data=abundance.plot,
geom=c("point","smooth"),
ylab="Average Abundance",
xlab="Year",
main="Average Abundnace timeseries for Standard SEAMAP trawl")
qplot(yr, effort, data=eff.plot,
geom=c("point", "smooth"),
ylab="Fishing Effort",
xlab="Year",
main="Total shrimping effort timeseries for nwGOM")
names(bgsrec.dat2)
sum(bgsrec.dat2$SELECT_BGS[bgsrec.dat2$bycatch=='catch'])
sum(bgsrec.dat2$SELECT_BGS[bgsrec.dat2$bycatch=='high'])
sum(bgsrec.dat2$SELECT_BGS[bgsrec.dat2$bycatch=='rare'])
sum(bgsrec.dat2$SELECT_BGS[bgsrec.dat2$bycatch=='never'])
summary(bgsrec.dat2$YR)
sum(bgsrec.dat2$SELECT_BGS)
library(Hmisc)
install.packages("Hmisc")
mdb.get(file='C:\Users\Kevin.Purcell\Documents\seamap_2013\public_seamap_2013-7-3_dwnlded.mdb',
tables=c('BGSREC','CRUISES','ENVREC','INVREC','SHRREC','STAREC'))
mdb.get(file='C:\Users\Kevin.Purcell\Documents\seamap_2013\public_seamap_2013-7-3_dwnlded.mdb',
tables='BGSREC','CRUISES','ENVREC','INVREC','SHRREC','STAREC')
mdb.get(file='C:\Users\Kevin.Purcell\Documents\seamap_2013\public_seamap_2013-7-3_dwnlded.mdb')
mdb.get(file='C:\\Users\\Kevin.Purcell\\Documents\\seamap_2013\\public_seamap_2013-7-3_dwnlded.mdb')
library(Hmisc)
mdb.get(file='C:\\Users\\Kevin.Purcell\\Documents\\seamap_2013\\public_seamap_2013-7-3_dwnlded.mdb')
bgsrec.dat<-mdb.get(file='C:\\Users\\Kevin.Purcell\\Documents\\seamap_2013\\public_seamap_2013-7-3_dwnlded.mdb',
tables='BGSREC',
lowernames=TRUE)
bgsrec.dat<-mdb.get('C:\\Users\\Kevin.Purcell\\Documents\\seamap_2013\\public_seamap_2013-7-3_dwnlded.mdb',
tables='BGSREC',
lowernames=TRUE)
install.packages("twitterR")
install.packages("googleVis")
require(googleVis) ## googleVis 0.5.0-3
dat <- data.frame(Room=c("Room 1","Room 2","Room 3"),
Language=c("English", "German", "French"),
start=as.POSIXct(c("2014-03-14 14:00",
"2014-03-14 15:00",
"2014-03-14 14:30")),
end=as.POSIXct(c("2014-03-14 15:00",
"2014-03-14 16:00",
"2014-03-14 15:30")))
View(dat)
install.packages(c("adegenet", "ape", "boot", "class", "cluster", "data.table", "dplyr", "evaluate", "foreign", "gdata", "gplots", "gtools", "httpuv", "httr", "jsonlite", "KernSmooth", "lattice", "lme4", "markdown", "MASS", "Matrix", "mgcv", "nlme", "nnet", "pdfetch", "PopGenReport", "raster", "Rcpp", "RcppEigen", "rpart", "Rttf2pt1", "spatial", "stargazer", "xtable", "yaml", "zoo"))
View(dat)
library(slidify)
library(devtools)
install.packages("Rtools")
install.packages("Rtools")
install_github('rNotebook', 'ramnathv')
rNotebook::viewNotebook()
ggplot::ggmap(paris, extent="normal")
ggplot2::ggmap(paris, extent="normal")
install.packages("ggplot2")
install.packages("ggmap")
library(ggplot2)
library(ggmap)
ggmap(paris, extent="normal")
paris<-get_map(location="paris")
ggmap(paris, extent="normal")
beaufort<-"Beaufort, NC"
qmap(beaufort, zoom=14)
qmap(beaufort, zoom=14, source="osm")
install.packages("forams")
library(forams)
abc
data(NB)
View(NB)
abc(NB)
test<-abc(NB)
plot.abc(test)
plot(test)
text(x=14,y=20,"Test Year")
plot.abc
plot
plot.abc()
abc.plot
test
abc$wstatistic
abc$w
abc$W
test$W.stat
test
test$W.Stat
W.Stat
w<-test$W.Stat
test
test@W.Stat[[1]]
test@W.Stat
abc
TMBchlaS3day_20120816120000_x260_X290_y7_Y35_nx2147483647_ny2147483647 <- read.delim("C:/Users/Kevin.Purcell/Downloads/TMBchlaS3day_20120816120000_x260_X290_y7_Y35_nx2147483647_ny2147483647.xyz", header=F)
View(TMBchlaS3day_20120816120000_x260_X290_y7_Y35_nx2147483647_ny2147483647)
dat <- read.delim("C:/Users/Kevin.Purcell/Downloads/TMBchlaS3day_20120816120000_x260_X290_y7_Y35_nx2147483647_ny2147483647.xyz", header=F)
View(dat)
summary(dat)
dat2<-subset(dat, dat$V3!='NaN')
library(ggplot2)
qplot(V1,V2,data=dat2)
plot(dat2$v1, dat2$V2)
plot(dat2$V1,dat2$V2)
library(maps)
library(mapsdata)
library(mapdata)
map("worldHires", fill=T, col="grey", add=T)
plot(dat2$V1,dat2$V2)
map("worldHires", fill=T, col="grey", add=T)
qplot(V1,V2,data=dat2, colour=factor(V3))
qplot(V1,V2,data=dat2, colour=V3)
library(slidify)
HTML          | Content Cell
library(slidify)
getwd()
setwd("~/GitHub/RR4NOAA")
publish(title = 'RR4NOAA', 'index.html', host='rpubs')
